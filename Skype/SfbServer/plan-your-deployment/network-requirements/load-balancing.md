---
title: Skype for Business の負荷分散要件
ms.reviewer: ''
ms.author: v-cichur
author: cichur
manager: serdars
audience: ITPro
ms.topic: conceptual
ms.prod: skype-for-business-itpro
f1.keywords:
- NOCSH
localization_priority: Normal
ms.collection:
- IT_Skype16
- Strat_SB_Admin
ms.custom: ''
ms.assetid: 84489328-64a4-486c-9384-a3e5c8ed9c8b
description: '概要: Skype for Business Server を実装する前に、負荷分散に関する考慮事項を確認してください。'
ms.openlocfilehash: 7a3851b73443db6be12ef2fd1a875b034eafff74
ms.sourcegitcommit: 01087be29daa3abce7d3b03a55ba5ef8db4ca161
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 03/23/2021
ms.locfileid: "51095011"
---
# <a name="load-balancing-requirements-for-skype-for-business"></a>Skype for Business の負荷分散要件
 
**概要:** Skype for Business Server を実装する前に、負荷分散に関する考慮事項を確認してください。
  
負荷分散は、プール内のサーバー間でトラフィックを分散します。 フロントエンド プール、仲介サーバー プール、またはエッジ サーバー プールがある場合は、これらのプールの負荷分散を展開する必要があります。
  
Skype for Business Server では、クライアント間トラフィック用の負荷分散ソリューションとして、ドメイン ネーム システム (DNS) 負荷分散とハードウェア負荷分散 (HLB と略す場合が多い) の 2 種類がサポートされています。 DNS 負荷分散には、管理の簡単化、トラブルシューティングの効率化、Skype for Business Server トラフィックの多くを潜在的なハードウェア ロード バランサーの問題から分離する機能など、いくつかの利点があります。
  
展開内の各プールに適した負荷分散ソリューションを自分で決定しますが、次の制限に注意してください。 
  
- 内部エッジ インターフェイスと外部エッジ インターフェイスでは、同じ種類のロード バランシングを使用する必要があります。1 つのインターフェイスで DNS ロード バランシングを使用し、もう 1 つのインターフェイスでロード バランサー機器を使用することはできません。
    
- 一部の種類のトラフィックでは、ハードウェア ロード バランサーが必要です。たとえば、HTTP トラフィックでは、DNS ロード バランシングではなくハードウェア ロード バランサーが必要です。クライアントとサーバー間の Web トラフィックでは、DNS ロード バランシングは正常に機能しません。
    
プールで DNS ロード バランシングを使用するように選択し、HTTP トラフィックなどのトラフィック用にハードウェア ロード バランサーも実装する必要がある場合、ハードウェア ロード バランサーの管理は非常に簡素化されます。 たとえば、ハードウェア ロード バランサーの構成は HTTP トラフィックと HTTPS トラフィックのみを管理し、他のすべてのプロトコルは DNS 負荷分散によって管理されるので、より簡単です。 詳細については、「[DNS Load Balancing](load-balancing.md#BKMK_DNSLoadBalancing)」を参照してください。 
  
サーバー間トラフィックの場合、Skype for Business Server はトポロジ対応の負荷分散を使用します。 サーバーは、サーバーの全体管理ストアで公開されたトポロジを読み取り、トポロジ内のサーバーの FQDN を取得し、サーバー間でトラフィックを自動的に分散します。 管理者は、この種類の負荷分散を設定または管理する必要は一方ではありません。 
  
DNS 負荷分散を使用し、特定のコンピューターへのトラフィックをブロックする必要がある場合は、プール FQDN から IP アドレス エントリを削除するだけで十分ではありません。 コンピューターの DNS エントリも削除する必要があります。 
  
## <a name="hardware-load-balancer-requirements"></a>ハードウェア ロード バランサーの要件

Skype for Business Server の拡張統合エッジ トポロジは、主に Skype for Business Server または Lync Server を使用する他の組織とフェデレーションする新しい展開の DNS 負荷分散用に最適化されています。 次のいずれかのシナリオで高可用性が必要な場合は、次の目的で、エッジ サーバー プールでハードウェア ロード バランサーを使用する必要があります。 
  
- コミュニケーション サーバー 2007 R2 または Officeコミュニケーション サーバー 2007 Office組織とのフェデレーション
    
- Exchange 2010 SP1 より前の Exchange UM を使用するリモート ユーザー用の Exchange UM
    
- パブリック IM ユーザーとの接続
    
> [!IMPORTANT]
> 1 つのインターフェイスでハードウェア負荷分散を使用し、もう 1 つのインターフェイスで DNS 負荷分散を使用することはできません。両方のインターフェイスでハードウェア負荷分散を使用するか、両方で DNS 負荷分散を使用する必要があります。 
  
> [!NOTE]
> ロード バランザー機器を使用している場合は、内部ネットワークとの接続用に展開されているロード バランザーを構成して、アクセス エッジ サービスおよび音声ビデオ サービスを実行しているサーバーへのトラフィックのみを負荷分散する必要があります。内部の Web 会議エッジ サービスまたは内部 XMPP プロキシ サービスへのトラフィックを負荷分散することはできません。 
  
> [!NOTE]
> 直接サーバーリターン (DSR) NAT は、Skype for Business Server ではサポートされていません。 
  
ハードウェア ロード バランサーが Skype for Business Server で必要な必要な機能をサポートするかどうかを確認するには [、「Infrastructure for Skype for Business」を参照してください](../../../SfbPartnerCertification/certification/infra-gateways.md)。 
  
### <a name="hardware-load-balancer-requirements-for-edge-servers-running-the-av-edge-service"></a>音声ビデオ エッジ サービスを実行するエッジ サーバーに対するロード バランサー機器の要件

A/V Edge サービスを実行するエッジ サーバーのハードウェア ロード バランサー要件は次のとおりです。
  
- 内部と外部の両方のポート 443 に対して TCP のネーグル処理がオフになっていること。ネーグル処理はいくつかの小さなパケットを 1 つの大きなパケットにまとめて転送効率を向上させるプロセスです。
    
- 外部ポート範囲 50,000 ~ 59,999 の TCP ナグリングをオフにします。 
    
- 内部または外部のファイアウォールで NAT が使用されていないこと。 
    
- エッジの内部インターフェイスがエッジ サーバーの外部インターフェイスとは別のネットワークに存在し、それらの間のルーティングが無効になっていること。 
    
- A/V エッジ サービスを実行するエッジ サーバーの外部インターフェイスでは、パブリックに送信可能な IP アドレスを使用し、エッジ外部 IP アドレスに NAT またはポート変換を使用する必要はありません。 
    
- ロード バランサーは、クライアントのソース アドレスを変更しなく必要があります。
    
### <a name="other-hardware-load-balancer-requirements"></a>その他のハードウェア ロード バランサーの要件

Skype for Business Server for Web サービスでは、Cookie ベースのアフィニティ要件が大幅に削減されます。 Skype for Business Server を展開し、Lync Server 2010 フロントエンド サーバーまたはフロントエンド プールを保持しない場合は、Cookie ベースの永続性は必要ではありません。 ただし、Lync Server 2010 フロントエンド サーバーまたはフロント エンド プールを一時的または完全に保持する場合でも、Lync Server 2010 用に展開および構成された Cookie ベースの永続性を使用します。 
  
> [!NOTE]
> **展開では不要だが、Cookie ベースのアフィニティを使用する場合でも**、悪影響はありません。 
  
Cookie ベースのアフィニティを **使用しない** 展開の場合
  
- リバース プロキシのポート 4443 に対する公開ルールで、[**ホスト ヘッダーを転送する**] が True に設定します。これにより、元の URL が確実に転送されます。
    
Cookie ベースのアフィニティを **使用する** 展開の場合
  
- リバース プロキシのポート 4443 に対する公開ルールで、[**ホスト ヘッダーを転送する**] が True に設定します。これにより、元の URL が確実に転送されます。
    
- ロード バランサー機器 Cookie が httpOnly とマークされていないこと
    
- ロード バランサー機器 Cookie に有効期限がないこと
    
- ロード バランサー機器 Cookie の名前が **MS-WSMAN** であること (これは Web サービスが受け取ることを想定している値であり、変更できません)
    
- ロード バランサー機器着信 HTTP 要求に Cookie が含まれていなかったすべての HTTP 応答に Cookie が設定されていること。同じ TCP 接続での以前の HTTP 応答で Cookie がすでに取得されているかどうかは関係ありません。ロード バランサーによって、Cookie の挿入が TCP 接続ごとに 1 回のみ行われるように最適化されている場合は、その最適化を使用しないでください。
    
> [!NOTE]
> 一般的なハードウェア ロード バランサー構成では、ソース アドレスアフィニティと 20 分を使用します。TCP セッションの有効期間は、クライアントの使用状況やアプリケーションの操作によってセッション状態が維持されるので、Lync Server および Lync 2013 クライアントでは問題ありません。 
  
モバイル デバイスを展開する場合、ロード バランサー機器で、TCP セッション内の個々の要求を負荷分散できるようにする必要があります (実際には、ターゲット IP アドレスに基づいて個々の要求を負荷分散できる必要があります)。
  
> [!CAUTION]
> モバイル デバイスを展開する場合、ハードウェア ロード バランサーは、TCP 接続内の各要求を個別に負荷分散できる必要があります。 最新の Apple iOS モバイル アプリでは、トランスポート層セキュリティ (TLS) バージョン 1.2 が必要です。  
  
> [!CAUTION]
> サード パーティ製のハードウェア ロード バランサーの詳細については [、「Infrastructure for Skype for Business」を参照してください](../../../SfbPartnerCertification/certification/infra-gateways.md)。  
  
ディレクターおよびフロントエンド プールの Web サービスに対するロード バランサー機器の要件は次のとおりです。
  
- 内部 Web サービスの VIP で、ロード バランサー機器の送信元アドレスの永続性 (内部ポート 80、443) が設定されていること。 Skype for Business Server の場合、Source_addrは、セッション状態を維持するために、1 つの IP アドレスから送信される複数の接続が常に 1 つのサーバーに送信されます。
    
- TCP アイドル タイムアウトが 1,800 秒に設定されていること
    
- リバース プロキシと次ホップ プールのハードウェア ロード バランサーの間のファイアウォールで、リバース プロキシからハードウェア ロード バランサーへの https: ポート 4443 のトラフィックを許可するルールを作成します。 ポート 80、443、および 4443 をリッスンするようにロード バランサー機器を構成する必要があります。
    
### <a name="summary-of-hardware-load-balancer-affinity-requirements"></a>ロード バランサー機器のアフィニティ要件の概要

|**クライアント/ユーザーの場所**|**外部 Web サービスの FQDN のアフィニティ要件**|**内部 Web サービスの FQDN のアフィニティ要件**|
|:-----|:-----|:-----|
|Lync Web App (内部ユーザーと外部ユーザー)  <br/> モバイル デバイス (内部および外部ユーザー)  <br/> |アフィニティなし  <br/> |送信元アドレスのアフィニティ  <br/> |
|Lync Web App (外部ユーザーのみ)  <br/> モバイル デバイス (内部および外部ユーザー)  <br/> |アフィニティなし  <br/> |送信元アドレスのアフィニティ  <br/> |
|Lync Web App (内部ユーザーのみ)  <br/> モバイル デバイス (展開しない)  <br/> |アフィニティなし  <br/> |送信元アドレスのアフィニティ  <br/> |
   
### <a name="port-monitoring-for-hardware-load-balancers"></a>ロード バランサー機器のポート監視

特定のサービスがハードウェアまたは通信障害によって使用できないような状況を確認する目的で、ロード バランサー機器に対してポート監視を定義します。 たとえば、フロント エンド サーバー またはフロント エンド プールに障害が発生してフロント エンド サーバー サービス (RTCSRV) が停止した場合、HLB 監視によって Web サービス上のトラフィックの受信も停止する必要があります。 以下を監視する目的で、HLB にポート監視を実装します。
  
**フロントエンド サーバー ユーザー プール - HLB 内部インターフェイス**

|**仮想 IP/ポート**|**ノード ポート**|**ノード コンピューター/モニター**|**保存プロファイル**|**注**|
|:-----|:-----|:-----|:-----|:-----|
|\<pool\>web-int_mco_443_vs  <br/> 443  <br/> |443  <br/> |フロントエンド  <br/> 5061  <br/> |ソース  <br/> |HTTPS  <br/> |
|\<pool\>web-int_mco_80_vs  <br/> 80  <br/> |80  <br/> |フロントエンド  <br/> 5061  <br/> |ソース  <br/> |HTTP  <br/> |
   
**フロントエンド サーバー ユーザー プール - HLB 外部インターフェイス**

|**仮想 IP/ポート**|**ノード ポート**|**ノード コンピューター/モニター**|**保存プロファイル**|**注**|
|:-----|:-----|:-----|:-----|:-----|
|\<pool\>web_mco_443_vs  <br/> 443  <br/> |4443  <br/> |フロントエンド  <br/> 5061  <br/> |なし  <br/> |HTTPS  <br/> |
|\<pool\>web_mco_80_vs  <br/> 80  <br/> |8080  <br/> |フロントエンド  <br/> 5061  <br/> |なし  <br/> |HTTP  <br/> |
   
## <a name="dns-load-balancing"></a>DNS 負荷分散
<a name="BKMK_DNSLoadBalancing"> </a>

Skype for Business Server を使用すると、ネットワークでの負荷分散の管理オーバーヘッドを大幅に削減できるソフトウェア ソリューションである DNS 負荷分散が有効になります。 DNS 負荷分散は、SIP トラフィックやメディア トラフィックなど、Skype for Business Server に固有のネットワーク トラフィックを分散します。
  
DNS 負荷分散を展開すると、ハードウェア ロード バランサーに対する組織の管理オーバーヘッドが最小限に抑えることができます。 さらに、SIP トラフィックの負荷分散装置の構成ミスに関する問題に対応するために、複雑なトラブルシューティングを行う必要がなくなります。 サーバーをオフラインにできるようにサーバー接続を禁止することもできます。 また、DNS 負荷分散を使用して、ハードウェア ロード バランサーの問題が基本的な通話のルーティングなどの SIP トラフィックの要素に影響しないようにすることもできます。

次の図は、内部 DNS 負荷分散と外部 DNS 負荷分散の両方を含む例を示しています。 
  
**パブリック IPv4 アドレスを使用したエッジ ネットワークダイアグラム**

![DNS ネットワーク図の例](../../media/2cc9546e-5560-4d95-8fe4-65a792a0e9c3.png)
  
また、DNS 負荷分散を使用すると、すべての種類のトラフィックに対応するハードウェア ロード バランサーを使用していた場合よりもハードウェア ロード バランサーを低価格で購入できます。 Skype for Business Server との相互運用性認定テストに合格したロード バランサーを使用する必要があります。 ロード バランサーの相互運用性テストの詳細については [、「Lync Server 2010 Load Balancer Partners」を参照してください](../../../SfbPartnerCertification/lync-cert/qualified-ip-pbx-gateway.md)。 このコンテンツは、Skype for Business Server に適用されます。
  
DNS 負荷分散は、フロント エンド プール、エッジ サーバー プール、ディレクター プール、およびスタンドアロンの仲介サーバー プールでサポートされます。
  
DNS 負荷分散は、通常、アプリケーション レベルで実装されます。 アプリケーション (たとえば、Skype for Business を実行しているクライアント) は、プールの完全修飾ドメイン名 (FQDN) に対する DNS A および AAAA (IPv6 アドレス指定が使用されている場合) レコード クエリから返される IP アドレスの 1 つに接続して、プール内のサーバーへの接続を試行します。 
  
たとえば、プールに 3 つのフロントエンド サーバーがある場合、pool01.contoso.com が発生します。
  
- Skype for Business クエリ DNS を実行しているクライアントは、pool01.contoso.com。 クエリは 3 つの IP アドレスを返し、次のようにキャッシュします (必ずしもこの順序ではありません)。
    
    pool01.contoso.com 192.168.10.90
    
    pool01.contoso.com 192.168.10.91
    
    pool01.contoso.com 192.168.10.92
    
- クライアントは、IP アドレスの 1 つへの伝送制御プロトコル (TCP) 接続を確立します。 失敗した場合、クライアントはキャッシュ内の次の IP アドレスを試行します。
    
- TCP 接続が成功した場合、クライアントは TLS をネゴシエートして、サーバー上のプライマリ レジストラー pool01.contoso.com。
    
- クライアントが正常に接続せずにすべてのキャッシュされたエントリを試行すると、Skype for Business Server を実行しているサーバーが現時点で使用できないという通知がユーザーに表示されます。
    
> [!NOTE]
> DNS ベースの負荷分散は、DNS ラウンド ロビン (DNS RR) とは異なります。通常は、プール内のサーバーに対応する異なる順序の IP アドレスを提供するために DNS に依存して負荷分散を参照します。 通常、DNS RR は負荷分散のみを有効にしますが、フェールオーバーは有効にしません。 たとえば、DNS A および AAAA (IPv6 アドレス指定を使用している場合) クエリによって返される 1 つの IP アドレスへの接続が失敗した場合、接続は失敗します。 したがって、DNS ラウンド ロビン自体は、DNS ベースの負荷分散よりも信頼性が低い。 DNS ラウンド ロビンは、DNS 負荷分散と組み合わせて使用できます。 
  
DNS 負荷分散は、次の場合に使用されます。
  
- エッジ サーバーへのサーバー間 SIP の負荷分散
    
- 電話会議、応答グループ、通話パークなどのユニファイド コミュニケーション アプリケーション サービス (UCAS) アプリケーション自動応答負荷分散
    
- UCAS アプリケーションへの新しい接続を防止する ("ドレイン" とも呼ばれる)
    
- クライアントとエッジ サーバー間のすべてのクライアント間トラフィックの負荷分散
    
DNS 負荷分散は、次の場合は使用できません。
  
- ディレクターまたはフロント エンド サーバーへのクライアントからサーバーへの Web トラフィック
    
DNS 負荷分散とフェデレーション トラフィック:
  
DNS SRV クエリによって複数の DNS レコードが返される場合、Access Edge サービスは常に、数値の優先度が最も低く、数値の重みが最も高い DNS SRV レコードを選択します。 インターネット エンジニアリング タスク フォースドキュメント "サービスの場所を指定する DNS RR (DNS SRV)" [RFC 2782、DNS SRV RR](https://www.ietf.org/rfc/rfc2782.txt) は、複数の DNS SRV レコードが定義されている場合は、優先順位が最初に使用され、重みを指定します。 たとえば、DNS SRV レコード A の重みは 20 で、優先度は 40 で、DNS SRV レコード B の重みは 10、優先度は 50 です。 優先度 40 の DNS SRV レコード A が選択されます。 DNS SRV レコードの選択には、次のルールが適用されます。
  
- 優先度は最初と見なされます。 クライアントは、DNS SRV レコードによって定義されたターゲット ホストに、到達できる番号が最も低い優先度で接続を試みる必要があります。 同じ優先度を持つターゲットは、重みフィールドで定義された順序で試してください。
    
- 重みフィールドは、同じ優先度を持つエントリの相対的な重みを指定します。 重みを大きくすると、選択される確率が比例して高くなります。 DNS 管理者は、サーバーの選択が行えない場合は、重み 0 を使用する必要があります。 重みを 0 より大きいレコードが含まれている場合、重み 0 を持つレコードは、選択される可能性が非常に小さい必要があります。
    
優先度と重みが等しい複数の DNS SRV レコードが返される場合、Access Edge サービスは、DNS サーバーから最初に受信された SRV レコードを選択します。
  
### <a name="dns-load-balancing-on-front-end-pools-and-director-pools"></a>フロント エンド プールとディレクター プールの DNS 負荷分散

フロント エンド プールとディレクター プールの SIP トラフィックに DNS 負荷分散を使用できます。 DNS 負荷分散を展開している場合でも、クライアントとサーバー間の HTTPS トラフィックに対してのみ、これらのプールに引き続きハードウェア ロード バランサーを使用する必要があります。 ハードウェア ロード バランサーは、ポート 443 とポート 80 経由のクライアントからの HTTPS トラフィックに対して使用します。 
  
これらのプール用のハードウェア ロード バランサーは引き続き必要ですが、そのセットアップと管理は主に HTTP トラフィックに対するものであり、ハードウェア ロード バランサーの管理者にはなじみのあるものです。
  
#### <a name="dns-load-balancing-and-supporting-older-clients-and-servers"></a>DNS 負荷分散およびサポートされる以前のクライアントとサーバー

DNS 負荷分散は、Skype for Business Server または Lync Server 2010 を実行しているサーバー、および Lync 2013 および Skype for Business クライアントの自動フェールオーバーのみをサポートします。 以前のバージョンのクライアントと Office Communications Server は、DNS 負荷分散を実行しているプールに接続できますが、DNS 負荷分散が参照する最初のサーバーに接続できない場合は、プール内の別のサーバーにフェールオーバーできません。 
  
さらに、Exchange UM を使用している場合は、少なくとも Exchange 2010 SP1 を使用して Skype for Business Server DNS 負荷分散のサポートを受け取る必要があります。 以前のバージョンの Exchange を使用している場合、ユーザーは次の Exchange UM シナリオに対してフェールオーバー機能を使用しません。
  
- 自分の電話でエンタープライズボイスメールを再生する
    
- Exchange UM 自動応答から通話を転送する
    
他のすべての Exchange UM シナリオでは効果があります。
  
#### <a name="deploying-dns-load-balancing-on-front-end-pools-and-director-pools"></a>フロント エンド プールとディレクター プールへの DNS 負荷分散の展開
<a name="BK_FE_Dir"> </a>

フロント エンド プールとディレクター プールに DNS 負荷分散を展開するには、FQDN と DNS レコードでいくつか追加の手順を実行する必要があります。
  
- DNS 負荷分散を使用するプールには、DNS 負荷分散で使用される通常のプール FQDN (pool01.contoso.com など) と、プール内のサーバーの物理 IP に解決される FQDN と、プールの仮想 IP アドレスに解決されるプールの Web サービス (web01.contoso.com など) の別の FQDN が必要です。 
    
    トポロジ ビルダーで、プールの DNS 負荷分散を展開する場合は、プールの Web サービスに対してこの追加の FQDN を作成するには、[内部 Web サービス プール **の FQDN** の上書き] チェック ボックスをオンにして、[このプールの Web サービス URL の指定] ページに FQDN を入力する **必要** があります。
    
- DNS 負荷分散で使用される FQDN をサポートするには、プールの FQDN (pool01.contoso.com など) をプール内のすべてのサーバーの IP アドレス (192.168.1.1、192.168.1.2 など) に解決するように DNS をプロビジョニングする必要があります。現在展開されているサーバーの IP アドレスのみ含めるようにしてください。
    
    > [!CAUTION]
    > 複数のフロント エンド プールまたはフロント エンド サーバーがある場合、外部 Web サービスの FQDN は一意である必要があります。 たとえば、フロントエンド サーバーの外部 Web サービス FQDN を **pool01.contoso.com** として定義する場合、別のフロントエンド プールまたはフロント エンド サーバーに pool01.contoso.com を使用することはできません。 ディレクターも展開する場合、ディレクターまたはディレクター プールに対して定義される外部 Web サービス FQDN は、他のディレクターまたはディレクター プール、およびフロント エンド プールまたはフロント エンド サーバーから一意である必要があります。 内部 Web サービスを自己定義の FQDN で上書きする場合、各 FQDN は他のフロントエンド プール、ディレクター、またはディレクター プールから一意である必要があります。
  
### <a name="dns-load-balancing-on-edge-server-pools"></a>エッジ サーバー プールの DNS 負荷分散
<a name="BK_Edge"> </a>

エッジ サーバー プールに DNS 負荷分散を展開できます。 その場合、いくつかの考慮事項に注意する必要があります。
  
エッジ サーバーで DNS 負荷分散を使用する場合、次のシナリオではフェールオーバー機能を利用できません。
  
- Lync Server 2010 より前にリリースされた Skype for Business Server のバージョンを実行している組織とのフェデレーション。
    
- 現在サポートされている唯一の XMPP パートナーである Google Talk などの XMPP ベースのプロバイダーおよびサーバーに加えて、パブリック インスタント メッセージング (IM) サービス AOL および Yahoo!のユーザーとのインスタント メッセージ交換。
    
これらのシナリオは、プール内のすべてのエッジ サーバーが実行されている限り有効ですが、いずれかのエッジ サーバーが利用できなくなると、これらのシナリオでそのエッジ サーバーに送信されるすべての要求は、別のエッジ サーバーにルーティングされずに失敗します。
  
 Exchange UM を使用している場合は、少なくとも Exchange 2013 を使用して、エッジでの Skype for Business Server DNS 負荷分散のサポートを受け取る必要があります。 以前のバージョンの Exchange を使用する場合、リモート ユーザーは次の Exchange UM シナリオに対してフェールオーバー機能を使用しません。
  
- 自分の電話でエンタープライズボイスメールを再生する
    
- Exchange UM 自動応答から通話を転送する
    
他のすべての Exchange UM シナリオでは効果があります。
  
内部エッジ インターフェイスと外部エッジ インターフェイスでは、同じ種類のロード バランシングを使用する必要があります。1 つのエッジ インターフェイスで DNS ロード バランシングを使用し、もう 1 つのエッジ インターフェイスでロード バランサー機器を使用することはできません。
  
#### <a name="deploying-dns-load-balancing-on-edge-server-pools"></a>エッジ サーバー プールへの DNS 負荷分散の展開

エッジ サーバー プールの外部インターフェイスに DNS 負荷分散を展開するには、次の DNS エントリが必要です。
  
- Access Edge サービスでは、プール内のサーバーごとに 1 つのエントリが必要です。 各エントリは、アクセス エッジ サービス (sip.contoso.com など) の FQDN を、プール内のいずれかのエッジ サーバー上の Access Edge サービスの IP アドレスに解決する必要があります。
    
- Web 会議エッジ サービスでは、プール内のサーバーごとに 1 つのエントリが必要です。 各エントリは、Web 会議エッジ サービス (webconf.contoso.com など) の FQDN を、プール内のいずれかのエッジ サーバー上の Web 会議エッジ サービスの IP アドレスに解決する必要があります。
    
- オーディオ/ビデオ エッジ サービスでは、プール内のサーバーごとに 1 つのエントリが必要です。 各エントリは、オーディオ/ビデオ エッジ サービス (av.contoso.com など) の FQDN を、プール内のいずれかのエッジ サーバー上の A/V エッジ サービスの IP アドレスに解決する必要があります。
    
エッジ サーバー プールの内部インターフェイスに DNS ロード バランシングを展開するには、エッジ サーバー プールの内部 FQDN をプール内の各サーバーの IP アドレスに解決する 1 つの DNS A レコードを追加する必要があります。
  
### <a name="using-dns-load-balancing-on-mediation-server-pools"></a>仲介サーバー プールでの DNS 負荷分散の使用
<a name="BK_Mediation"> </a>

スタンドアロンの仲介サーバー プールで、DNS 負荷分散を使用できます。すべての SIP トラフィックとメディア トラフィックは DNS 負荷分散によって調整されます。
  
仲介サーバー プールに DNS 負荷分散を展開するには、プールの FQDN (mediationpool1.contoso.com など) をプール内のすべてのサーバーの IP アドレス (192.168.1.1、192.168.1.2 など) に解決するように DNS をプロビジョニングする必要があります。
  
### <a name="blocking-traffic-to-a-server-with-dns-load-balancing"></a>DNS 負荷分散を使用してサーバーへのトラフィックをブロックする
<a name="BK_Mediation"> </a>

DNS 負荷分散を使用し、特定のコンピューターへのトラフィックをブロックする必要がある場合は、プール FQDN から IP アドレス エントリを削除するだけで十分ではありません。 コンピューターの DNS エントリも削除する必要があります。 
  
サーバー間トラフィックの場合、Skype for Business Server はトポロジ対応の負荷分散を使用します。 サーバーは、サーバーの全体管理ストアで公開されたトポロジを読み取り、トポロジ内のサーバーの FQDN を取得し、サーバー間でトラフィックを自動的に分散します。 サーバー間トラフィックの受信をサーバーにブロックするには、トポロジからサーバーを削除する必要があります。 
