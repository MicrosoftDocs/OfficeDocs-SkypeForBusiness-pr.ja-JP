---
title: Skype for Business の負荷分散の要件
ms.reviewer: ''
ms.author: v-cichur
author: cichur
manager: serdars
audience: ITPro
ms.topic: conceptual
ms.prod: skype-for-business-itpro
f1.keywords:
- NOCSH
localization_priority: Normal
ms.collection:
- IT_Skype16
- Strat_SB_Admin
ms.custom: ''
ms.assetid: 84489328-64a4-486c-9384-a3e5c8ed9c8b
description: '概要: Skype for Business Server を実装する前に、負荷分散に関する考慮事項を確認します。'
ms.openlocfilehash: 5790ef1ba0d32774ced45be5af257f70fc4cf594
ms.sourcegitcommit: c528fad9db719f3fa96dc3fa99332a349cd9d317
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 01/12/2021
ms.locfileid: "49834377"
---
# <a name="load-balancing-requirements-for-skype-for-business"></a>Skype for Business の負荷分散の要件
 
**概要:** Skype for Business Server を実装する前に、負荷分散に関する考慮事項を確認してください。
  
負荷分散は、プール内のサーバー間でトラフィックを分散します。 フロントエンド プール、仲介サーバー プール、またはエッジ サーバー プールがある場合は、これらのプールの負荷分散を展開する必要があります。
  
Skype for Business Server は、クライアントからサーバーへのトラフィック用に 2 種類の負荷分散ソリューションをサポートしています。ドメイン ネーム システム (DNS) 負荷分散とハードウェア負荷分散 (HLB と省略される場合があります)。 DNS 負荷分散には、管理の簡易化、トラブルシューティングの効率化、Skype for Business Server トラフィックの多くをハードウェア ロード バランサーの潜在的な問題から切り離す機能など、いくつかの利点があります。
  
展開内の各プールに適した負荷分散ソリューションを自分で決定しますが、次の制限に注意してください。 
  
- 内部エッジ インターフェイスと外部エッジ インターフェイスでは、同じ種類のロード バランシングを使用する必要があります。1 つのインターフェイスで DNS ロード バランシングを使用し、もう 1 つのインターフェイスでロード バランサー機器を使用することはできません。
    
- 一部の種類のトラフィックでは、ハードウェア ロード バランサーが必要です。たとえば、HTTP トラフィックでは、DNS ロード バランシングではなくハードウェア ロード バランサーが必要です。クライアントとサーバー間の Web トラフィックでは、DNS ロード バランシングは正常に機能しません。
    
プールで DNS ロード バランシングを使用するように選択し、HTTP トラフィックなどのトラフィック用にハードウェア ロード バランサーも実装する必要がある場合、ハードウェア ロード バランサーの管理は非常に簡素化されます。 たとえば、ロード バランサーハードウェアの構成は HTTP トラフィックと HTTPS トラフィックのみを管理するのに対し、他のすべてのプロトコルは DNS 負荷分散によって管理されるので、構成が簡単です。 詳細については、「[DNS Load Balancing](load-balancing.md#BKMK_DNSLoadBalancing)」を参照してください。 
  
サーバー間トラフィックの場合、Skype for Business Server はトポロジ対応の負荷分散を使用します。 サーバーは中央管理ストアの公開トポロジを読み取り、トポロジ内のサーバーの FQDN を取得し、トラフィックをサーバー間で自動的に分散します。 管理者は、この種類の負荷分散を設定または管理する必要があります。 
  
DNS 負荷分散を使用し、特定のコンピューターへのトラフィックをブロックする必要がある場合は、プールの FQDN から IP アドレス エントリを削除するだけで十分ではありません。 コンピューターの DNS エントリも削除する必要があります。 
  
## <a name="hardware-load-balancer-requirements"></a>ロード バランサーのハードウェア要件

Skype for Business Server の拡張統合エッジ トポロジは、主に Skype for Business Server または Lync Server を使用する他の組織とフェデレーションする新しい展開向けに DNS 負荷分散用に最適化されています。 次のいずれかのシナリオで高可用性が必要な場合は、次の目的で、エッジ サーバー プールでハードウェア ロード バランサーを使用する必要があります。 
  
- Communications Server 2007 R2 または Office Communications Server 2007 を使用Office組織とのフェデレーション
    
- Exchange 2010 SP1 より前の Exchange UM を使用するリモート ユーザーの Exchange UM
    
- パブリック IM ユーザーとの接続
    
> [!IMPORTANT]
> 1 つのインターフェイスでハードウェア負荷分散を使用し、もう 1 つのインターフェイスで DNS 負荷分散を使用することはできません。両方のインターフェイスでハードウェア負荷分散を使用するか、両方で DNS 負荷分散を使用する必要があります。 
  
> [!NOTE]
> ロード バランザー機器を使用している場合は、内部ネットワークとの接続用に展開されているロード バランザーを構成して、アクセス エッジ サービスおよび音声ビデオ サービスを実行しているサーバーへのトラフィックのみを負荷分散する必要があります。内部の Web 会議エッジ サービスまたは内部 XMPP プロキシ サービスへのトラフィックを負荷分散することはできません。 
  
> [!NOTE]
> 直接サーバー リターン (DSR) NAT は、Skype for Business Server ではサポートされていません。 
  
ハードウェア ロード バランサーが Skype for Business Server に必要な機能をサポートするかどうかを確認するには、「Skype for Business のインフラストラクチャ」 [を参照してください](https://docs.microsoft.com/SkypeForBusiness/certification/infra-gateways)。 
  
### <a name="hardware-load-balancer-requirements-for-edge-servers-running-the-av-edge-service"></a>音声ビデオ エッジ サービスを実行するエッジ サーバーに対するロード バランサー機器の要件

A/V エッジ サービスを実行するエッジ サーバーのハードウェア ロード バランサー要件は次のとおりです。
  
- 内部と外部の両方のポート 443 に対して TCP のネーグル処理がオフになっていること。ネーグル処理はいくつかの小さなパケットを 1 つの大きなパケットにまとめて転送効率を向上させるプロセスです。
    
- 外部ポート範囲 50,000 ~ 59,999 の TCP の入れ子をオフにします。 
    
- 内部または外部のファイアウォールで NAT が使用されていないこと。 
    
- エッジの内部インターフェイスがエッジ サーバーの外部インターフェイスとは別のネットワークに存在し、それらの間のルーティングが無効になっていること。 
    
- A/V エッジ サービスを実行するエッジ サーバーの外部インターフェイスは、パブリックにログアウト可能な IP アドレスを使用し、エッジ外部 IP アドレスに NAT またはポート変換を使用する必要はありません。 
    
- ロード バランサーは、クライアントのソース アドレスを変更する必要があります。
    
### <a name="other-hardware-load-balancer-requirements"></a>その他のハードウェア ロード バランサーの要件

Skype for Business Server for Web サービスでは、Cookie ベースのアフィニティ要件が大幅に削減されます。 Skype for Business Server を展開し、Lync Server 2010 フロントエンド サーバーまたはフロントエンド プールを保持しない場合は、Cookie ベースの永続性は必要ではありません。 ただし、Lync Server 2010 フロントエンド サーバーまたはフロントエンド プールを一時的または永続的に保持する場合は、Lync Server 2010 用に展開および構成された Cookie ベースの永続性を引き続き使用します。 
  
> [!NOTE]
> **展開では不要だが、Cookie ベースのアフィニティを使用する場合でも**、悪影響はありません。 
  
Cookie ベースのアフィニティを **使用しない** 展開の場合
  
- リバース プロキシのポート 4443 に対する公開ルールで、[**ホスト ヘッダーを転送する**] が True に設定します。これにより、元の URL が確実に転送されます。
    
Cookie ベースのアフィニティを **使用する** 展開の場合
  
- リバース プロキシのポート 4443 に対する公開ルールで、[**ホスト ヘッダーを転送する**] が True に設定します。これにより、元の URL が確実に転送されます。
    
- ロード バランサー機器 Cookie が httpOnly とマークされていないこと
    
- ロード バランサー機器 Cookie に有効期限がないこと
    
- ロード バランサー機器 Cookie の名前が **MS-WSMAN** であること (これは Web サービスが受け取ることを想定している値であり、変更できません)
    
- ロード バランサー機器着信 HTTP 要求に Cookie が含まれていなかったすべての HTTP 応答に Cookie が設定されていること。同じ TCP 接続での以前の HTTP 応答で Cookie がすでに取得されているかどうかは関係ありません。ロード バランサーによって、Cookie の挿入が TCP 接続ごとに 1 回のみ行われるように最適化されている場合は、その最適化を使用しないでください。
    
> [!NOTE]
> 一般的なハードウェア ロード バランサー構成では、送信元アドレス アフィニティと 20 分の TCP セッションの有効期間を使用します。これは、クライアントの使用状況やアプリケーションのやり取りによってセッション状態が維持されるので、Lync Server および Lync 2013 クライアントで問題ありません。 
  
モバイル デバイスを展開する場合、ロード バランサー機器で、TCP セッション内の個々の要求を負荷分散できるようにする必要があります (実際には、ターゲット IP アドレスに基づいて個々の要求を負荷分散できる必要があります)。
  
> [!CAUTION]
> モバイル デバイスを展開する場合は、ハードウェア ロード バランサーが TCP 接続内の各要求を個別に負荷分散できる必要があります。 最新の Apple iOS モバイル アプリには、トランスポート層セキュリティ (TLS) バージョン 1.2 が必要です。  
  
> [!CAUTION]
> サード パーティ製ハードウェア ロード バランサーの詳細については [、「Skype for Business のインフラストラクチャ」を参照してください](https://docs.microsoft.com/SkypeForBusiness/certification/infra-gateways)。  
  
ディレクターおよびフロントエンド プールの Web サービスに対するロード バランサー機器の要件は次のとおりです。
  
- 内部 Web サービスの VIP で、ロード バランサー機器の送信元アドレスの永続性 (内部ポート 80、443) が設定されていること。 Skype for Business Server の場合、Source_addrは、1 つの IP アドレスから複数の接続が常に 1 つのサーバーに送信され、セッション状態が維持されます。
    
- TCP アイドル タイムアウトが 1,800 秒に設定されていること
    
- リバース プロキシと次ホップ プールのハードウェア ロード バランサーの間のファイアウォールで、リバース プロキシからハードウェア ロード バランサーへの https: トラフィックをポート 4443 で許可するルールを作成します。 ポート 80、443、および 4443 をリッスンするようにロード バランサー機器を構成する必要があります。
    
### <a name="summary-of-hardware-load-balancer-affinity-requirements"></a>ロード バランサー機器のアフィニティ要件の概要

|**クライアント/ユーザーの場所**|**外部 Web サービスの FQDN のアフィニティ要件**|**内部 Web サービスの FQDN のアフィニティ要件**|
|:-----|:-----|:-----|
|Lync Web App (内部ユーザーと外部ユーザー)  <br/> モバイル デバイス (内部および外部ユーザー)  <br/> |アフィニティなし  <br/> |送信元アドレスのアフィニティ  <br/> |
|Lync Web App (外部ユーザーのみ)  <br/> モバイル デバイス (内部および外部ユーザー)  <br/> |アフィニティなし  <br/> |送信元アドレスのアフィニティ  <br/> |
|Lync Web App (内部ユーザーのみ)  <br/> モバイル デバイス (展開しない)  <br/> |アフィニティなし  <br/> |送信元アドレスのアフィニティ  <br/> |
   
### <a name="port-monitoring-for-hardware-load-balancers"></a>ロード バランサー機器のポート監視

特定のサービスがハードウェアまたは通信障害によって使用できないような状況を確認する目的で、ロード バランサー機器に対してポート監視を定義します。 たとえば、フロントエンド サーバーまたはフロント エンド プールに障害が発生してフロントエンド サーバー サービス (RTCSRV) が停止した場合、HLB 監視は Web サービス上のトラフィックの受信も停止する必要があります。 以下を監視する目的で、HLB にポート監視を実装します。
  
**フロントエンド サーバーのユーザー プール - HLB 内部インターフェイス**

|**仮想 IP/ポート**|**ノード ポート**|**ノード コンピューター/モニター**|**保存プロファイル**|**注**|
|:-----|:-----|:-----|:-----|:-----|
|\<pool\>web-int_mco_443_vs  <br/> 443  <br/> |443  <br/> |フロントエンド  <br/> 5061  <br/> |ソース  <br/> |HTTPS  <br/> |
|\<pool\>web-int_mco_80_vs  <br/> 80  <br/> |80  <br/> |フロントエンド  <br/> 5061  <br/> |ソース  <br/> |HTTP  <br/> |
   
**フロントエンド サーバーのユーザー プール - HLB 外部インターフェイス**

|**仮想 IP/ポート**|**ノード ポート**|**ノード コンピューター/モニター**|**保存プロファイル**|**注**|
|:-----|:-----|:-----|:-----|:-----|
|\<pool\>web_mco_443_vs  <br/> 443  <br/> |4443  <br/> |フロントエンド  <br/> 5061  <br/> |なし  <br/> |HTTPS  <br/> |
|\<pool\>web_mco_80_vs  <br/> 80  <br/> |8080  <br/> |フロントエンド  <br/> 5061  <br/> |なし  <br/> |HTTP  <br/> |
   
## <a name="dns-load-balancing"></a>DNS 負荷分散
<a name="BKMK_DNSLoadBalancing"> </a>

Skype for Business Server を使用すると、DNS 負荷分散が可能になります。これは、ネットワーク上の負荷分散の管理オーバーヘッドを大幅に削減できるソフトウェア ソリューションです。 DNS 負荷分散は、SIP トラフィックやメディア トラフィックなど、Skype for Business Server に固有のネットワーク トラフィックを分散します。
  
DNS 負荷分散を展開すると、ハードウェア ロード バランサーに対する組織の管理オーバーヘッドが最小限に抑えることができます。 さらに、SIP トラフィックの負荷分散装置の構成ミスに関する問題に対応するために、複雑なトラブルシューティングを行う必要がなくなります。 サーバーをオフラインにできるようにサーバー接続を禁止することもできます。 また、DNS 負荷分散を使用して、ハードウェア ロード バランサーの問題が基本的な通話のルーティングなどの SIP トラフィックの要素に影響しないようにすることもできます。

次の図は、内部と外部の両方の DNS 負荷分散を含む例を示しています。 
  
**パブリック IPv4 アドレスを使用したエッジ ネットワーク図**

![DNS ネットワークダイアグラムの例](../../media/2cc9546e-5560-4d95-8fe4-65a792a0e9c3.png)
  
また、DNS 負荷分散を使用すると、すべての種類のトラフィックに対応するハードウェア ロード バランサーを使用していた場合よりもハードウェア ロード バランサーを低価格で購入できます。 Skype for Business Server との相互運用性の認定テストに合格したロード バランサーを使用する必要があります。 ロード バランサー相互運用性テストの詳細については [、「Lync Server 2010 Load Balancer Partners」を参照してください](https://go.microsoft.com/fwlink/p/?linkId=202452)。 Skype for Business Server に適用されるコンテンツ。
  
DNS 負荷分散は、フロント エンド プール、エッジ サーバー プール、ディレクター プール、およびスタンドアロンの仲介サーバー プールでサポートされます。
  
DNS 負荷分散は、通常、アプリケーション レベルで実装されます。 アプリケーション (Skype for Business を実行しているクライアントなど) は、プールの完全修飾ドメイン名 (FQDN) に対する DNS A および AAAA (IPv6 アドレスが使用されている場合) レコード クエリから返された IP アドレスの 1 つに接続して、プール内のサーバーへの接続を試行します。 
  
たとえば、pool01.contoso.com という名前のプールに 3 つのフロントエンド サーバーがある場合、次のことが発生します。
  
- Skype for Business を実行しているクライアントは、DNS にクエリをpool01.contoso.com。 クエリは 3 つの IP アドレスを返し、次のようにキャッシュします (必ずしもこの順序ではありません)。
    
    pool01.contoso.com 192.168.10.90
    
    pool01.contoso.com 192.168.10.91
    
    pool01.contoso.com 192.168.10.92
    
- クライアントは、IP アドレスの 1 つへの伝送制御プロトコル (TCP) 接続を確立します。 これが失敗した場合、クライアントはキャッシュ内の次の IP アドレスを試行します。
    
- TCP 接続が成功すると、クライアントは TLS をネゴシエートして、サーバー上のプライマリ レジストラー pool01.contoso.com。
    
- クライアントが接続に成功せずにすべてのキャッシュされたエントリを試行すると、Skype for Business Server を実行しているサーバーが現時点で使用できないという通知がユーザーに表示されます。
    
> [!NOTE]
> DNS ベースの負荷分散は、DNS ラウンド ロビン (DNS RR) とは異なります。DNS ラウンド ロビン (DNS RR) は、通常、DNS に依存してプール内のサーバーに対応する異なる順序の IP アドレスを提供することで負荷分散を指します。 通常、DNS RR は負荷分散のみを有効にしますが、フェールオーバーは有効にしません。 たとえば、DNS A および AAAA (IPv6 アドレス指定を使用している場合) クエリによって返される 1 つの IP アドレスへの接続が失敗した場合、接続は失敗します。 したがって、DNS ラウンド ロビン自体は DNS ベースの負荷分散よりも信頼性が低い。 DNS ラウンド ロビンは、DNS 負荷分散と組み合わせて使用できます。 
  
DNS 負荷分散は、次の場合に使用されます。
  
- エッジ サーバーへのサーバー間 SIP の負荷分散
    
- 電話会議、応答グループ、コール パークなどのユニファイド コミュニケーション アプリケーション サービス (UCAS) アプリケーション自動応答負荷分散
    
- UCAS アプリケーションへの新しい接続の防止 ("ドレイン" とも呼ばれる)
    
- クライアントとエッジ サーバー間のすべてのクライアント間トラフィックの負荷分散
    
DNS 負荷分散は、次の場合には使用できません。
  
- ディレクターまたはフロントエンド サーバーへのクライアントからサーバーへの Web トラフィック
    
DNS 負荷分散とフェデレーション トラフィック:
  
DNS SRV クエリによって複数の DNS レコードが返される場合、アクセス エッジ サービスは常に、数値の優先順位が最も低く数値ウェイトが最も高い DNS SRV レコードを選択します。 Internet Engineering Task Force ドキュメント「A DNS RR for specifying the location of services (DNS SRV)」RFC [2782、DNS SRV RR](https://www.ietf.org/rfc/rfc2782.txt) では、定義されている DNS SRV レコードが複数ある場合、優先順位が最初に使用され、重み付けされます。 たとえば、DNS SRV レコード A の重み付けは 20、優先度は 40、DNS SRV レコード B の重みは 10、優先度は 50 です。 優先度 40 の DNS SRV レコード A が選択されます。 DNS SRV レコードの選択には、次のルールが適用されます。
  
- 優先度が最初に考慮されます。 クライアントは、DNS SRV レコードによって定義されたターゲット ホストに、到達可能な番号付き優先順位が最も低いホストに接続を試みる必要があります。 優先度が同じターゲットは、重みフィールドで定義された順序で試される必要があります。
    
- 重みフィールドは、同じ優先度を持つエントリの相対的な重みを指定します。 重みを大きくすると、選択される確率が比例して高くなります。 DNS 管理者は、実行するサーバーが選択されていない場合は、重み 0 を使用する必要があります。 重み付けが 0 より大きいレコードがある場合、重み付け 0 のレコードが選択される可能性は非常に小さい必要があります。
    
同じ優先度と重みを持つ複数の DNS SRV レコードが返された場合、アクセス エッジ サービスは DNS サーバーから最初に受信した SRV レコードを選択します。
  
### <a name="dns-load-balancing-on-front-end-pools-and-director-pools"></a>フロント エンド プールとディレクター プールの DNS 負荷分散

フロント エンド プールとディレクター プールの SIP トラフィックに DNS 負荷分散を使用できます。 DNS 負荷分散を展開している場合でも、クライアントとサーバー間の HTTPS トラフィックに対してのみ、これらのプールに引き続きハードウェア ロード バランサーを使用する必要があります。 ハードウェア ロード バランサーは、ポート 443 とポート 80 経由のクライアントからの HTTPS トラフィックに対して使用します。 
  
これらのプール用のハードウェア ロード バランサーは引き続き必要ですが、そのセットアップと管理は主に HTTP トラフィックに対するものであり、ハードウェア ロード バランサーの管理者にはなじみのあるものです。
  
#### <a name="dns-load-balancing-and-supporting-older-clients-and-servers"></a>DNS 負荷分散およびサポートされる以前のクライアントとサーバー

DNS 負荷分散は、Skype for Business Server または Lync Server 2010 を実行しているサーバー、および Lync 2013 および Skype for Business クライアントに対する自動フェールオーバーのみをサポートします。 以前のバージョンのクライアントと Office Communications Server は DNS 負荷分散を実行しているプールに接続できますが、DNS 負荷分散が参照する最初のサーバーに接続できない場合は、プール内の別のサーバーにフェールオーバーできません。 
  
また、Exchange UM を使用している場合は、最低でも Exchange 2010 SP1 を使用して Skype for Business Server DNS 負荷分散のサポートを受け取る必要があります。 以前のバージョンの Exchange を使用している場合、ユーザーは次の Exchange UM シナリオに対するフェールオーバー機能を使用しません。
  
- 電話でのエンタープライズ ボイスメールの再生
    
- Exchange UM 自動応答から通話を転送する
    
他のすべての Exchange UM シナリオでは効果があります。
  
#### <a name="deploying-dns-load-balancing-on-front-end-pools-and-director-pools"></a>フロント エンド プールとディレクター プールへの DNS 負荷分散の展開
<a name="BK_FE_Dir"> </a>

フロント エンド プールとディレクター プールに DNS 負荷分散を展開するには、FQDN と DNS レコードでいくつか追加の手順を実行する必要があります。
  
- DNS 負荷分散を使用するプールには、DNS 負荷分散で使用される通常のプール FQDN (pool01.contoso.com など) と、プール内のサーバーの物理 IP に解決される 2 つの FQDN と、プールの仮想 IP アドレスに解決されるプールの Web サービス用の別の FQDN (web01.contoso.com など) が必要です。 
    
    トポロジ ビルダーでプールの DNS 負荷分散を展開する場合は、プールの Web サービスにこの追加の FQDN を作成するには、[内部 Web サービス プール **の FQDN** を上書きする] チェック ボックスをオンにして、FQDN を [このプールの **Web** サービス URL の指定] ページに入力する必要があります。
    
- DNS 負荷分散で使用される FQDN をサポートするには、プールの FQDN (pool01.contoso.com など) をプール内のすべてのサーバーの IP アドレス (192.168.1.1、192.168.1.2 など) に解決するように DNS をプロビジョニングする必要があります。現在展開されているサーバーの IP アドレスのみ含めるようにしてください。
    
    > [!CAUTION]
    > 複数のフロントエンド プールまたはフロントエンド サーバーがある場合、外部 Web サービスの FQDN は一意である必要があります。 たとえば、フロントエンド サーバーの外部 Web サービス FQDN を **pool01.contoso.com** として定義する場合、別のフロントエンド プールまたはフロントエンド サーバーに **pool01.contoso.com** を使用することはできません。 ディレクターも展開する場合、ディレクターまたはディレクター プールに対して定義された外部 Web サービスの FQDN は、他のディレクターまたはディレクター プール、およびフロントエンド プールまたはフロントエンド サーバーから一意である必要があります。 内部 Web サービスを自己定義の FQDN で上書きする場合、各 FQDN は他のフロントエンド プール、ディレクター、またはディレクター プールから一意である必要があります。
  
### <a name="dns-load-balancing-on-edge-server-pools"></a>エッジ サーバー プールの DNS 負荷分散
<a name="BK_Edge"> </a>

エッジ サーバー プールに DNS 負荷分散を展開できます。 その場合、いくつかの考慮事項に注意する必要があります。
  
エッジ サーバーで DNS 負荷分散を使用する場合、次のシナリオではフェールオーバー機能を利用できません。
  
- Lync Server 2010 より前にリリースされたバージョンの Skype for Business Server を実行している組織とのフェデレーション。
    
- 現在サポートされている唯一の XMPP パートナーである Google Talk などの XMPP ベースのプロバイダーおよびサーバーに加えて、パブリック インスタント メッセージング (IM) サービス AOL および Yahoo! のユーザーとのインスタント メッセージ交換。
    
これらのシナリオは、プール内のすべてのエッジ サーバーが実行されている限り有効ですが、いずれかのエッジ サーバーが利用できなくなると、これらのシナリオでそのエッジ サーバーに送信されるすべての要求は、別のエッジ サーバーにルーティングされずに失敗します。
  
 Exchange UM を使用している場合は、最低でも Exchange 2013 を使用して、エッジでの Skype for Business Server DNS 負荷分散のサポートを受け取る必要があります。 以前のバージョンの Exchange を使用している場合、リモート ユーザーは次の Exchange UM シナリオに対するフェールオーバー機能を使用しません。
  
- 電話でのエンタープライズ ボイスメールの再生
    
- Exchange UM 自動応答から通話を転送する
    
他のすべての Exchange UM シナリオでは効果があります。
  
内部エッジ インターフェイスと外部エッジ インターフェイスでは、同じ種類のロード バランシングを使用する必要があります。1 つのエッジ インターフェイスで DNS ロード バランシングを使用し、もう 1 つのエッジ インターフェイスでロード バランサー機器を使用することはできません。
  
#### <a name="deploying-dns-load-balancing-on-edge-server-pools"></a>エッジ サーバー プールへの DNS 負荷分散の展開

エッジ サーバー プールの外部インターフェイスに DNS 負荷分散を展開するには、次の DNS エントリが必要です。
  
- アクセス エッジ サービスでは、プール内のサーバーごとに 1 つのエントリが必要です。 各エントリは、アクセス エッジ サービスの FQDN (sip.contoso.com など) をプール内のいずれかのエッジ サーバー上のアクセス エッジ サービスの IP アドレスに解決する必要があります。
    
- Web 会議エッジ サービスでは、プール内のサーバーごとに 1 つのエントリが必要です。 各エントリは、Web 会議エッジ サービス (webconf.contoso.com など) の FQDN を、プール内のいずれかのエッジ サーバー上の Web 会議エッジ サービスの IP アドレスに解決する必要があります。
    
- 音声ビデオ エッジ サービスでは、プール内のサーバーごとに 1 つのエントリが必要です。 各エントリは、音声ビデオ エッジ サービス (av.contoso.com など) の FQDN を、プール内のいずれかのエッジ サーバー上の音声ビデオ エッジ サービスの IP アドレスに解決する必要があります。
    
エッジ サーバー プールの内部インターフェイスに DNS ロード バランシングを展開するには、エッジ サーバー プールの内部 FQDN をプール内の各サーバーの IP アドレスに解決する 1 つの DNS A レコードを追加する必要があります。
  
### <a name="using-dns-load-balancing-on-mediation-server-pools"></a>仲介サーバー プールでの DNS 負荷分散の使用
<a name="BK_Mediation"> </a>

スタンドアロンの仲介サーバー プールで、DNS 負荷分散を使用できます。すべての SIP トラフィックとメディア トラフィックは DNS 負荷分散によって調整されます。
  
仲介サーバー プールに DNS 負荷分散を展開するには、プールの FQDN (mediationpool1.contoso.com など) をプール内のすべてのサーバーの IP アドレス (192.168.1.1、192.168.1.2 など) に解決するように DNS をプロビジョニングする必要があります。
  
### <a name="blocking-traffic-to-a-server-with-dns-load-balancing"></a>DNS 負荷分散を使用したサーバーへのトラフィックのブロック
<a name="BK_Mediation"> </a>

DNS 負荷分散を使用し、特定のコンピューターへのトラフィックをブロックする必要がある場合は、プールの FQDN から IP アドレス エントリを削除するだけで十分ではありません。 コンピューターの DNS エントリも削除する必要があります。 
  
サーバー間トラフィックの場合、Skype for Business Server はトポロジ対応の負荷分散を使用します。 サーバーは中央管理ストアの公開トポロジを読み取り、トポロジ内のサーバーの FQDN を取得し、トラフィックをサーバー間で自動的に分散します。 サーバーがサーバー間トラフィックを受信するのをブロックするには、トポロジからサーバーを削除する必要があります。 
  

